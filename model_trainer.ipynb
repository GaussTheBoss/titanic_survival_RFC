{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=\"INFO\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Check library versions\n",
    "logger.info(\"pandas==%s\", pandas.__version__)\n",
    "logger.info(\"numpy==%s\", numpy.__version__)\n",
    "logger.info(\"scikit-learn==%s\", sklearn.__version__)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:pandas==1.1.5\n",
      "INFO:__main__:numpy==1.19.5\n",
      "INFO:__main__:scikit-learn==0.22\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Loding Training Data\n",
    "training_data = pandas.read_csv(\"train.csv\")\n",
    "logger.info(\"training_data.shape: %s\", training_data.shape)\n",
    "logger.info(\"Sample Trainning Data: \\n %s\", training_data.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:training_data.shape: (571, 12)\n",
      "INFO:__main__:Sample Trainning Data: \n",
      "    PassengerId  Pclass                              Name     Sex   Age  SibSp  \\\n",
      "0          145       2        Andrew, Mr. Edgardo Samuel    male  18.0      0   \n",
      "1          531       2          Quick, Miss. Phyllis May  female   2.0      1   \n",
      "2          387       3   Goodwin, Master. Sidney Leonard    male   1.0      5   \n",
      "3           94       3           Dean, Mr. Bertram Frank    male  26.0      1   \n",
      "4          753       3  Vande Velde, Mr. Johannes Joseph    male  33.0      0   \n",
      "\n",
      "   Parch     Ticket    Fare Cabin Embarked  Survived  \n",
      "0      0     231945  11.500   NaN        S         0  \n",
      "1      1      26360  26.000   NaN        S         1  \n",
      "2      2    CA 2144  46.900   NaN        S         0  \n",
      "3      2  C.A. 2315  20.575   NaN        S         0  \n",
      "4      0     345780   9.500   NaN        S         0  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Define predictors and target variable\n",
    "numeric_predictors = [\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]\n",
    "categorical_predictors = [\"Sex\", \"Cabin\", \"Embarked\"]\n",
    "target_variable = \"Survived\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Filtering trainng data to predictors + target\n",
    "training_data = training_data[numeric_predictors+categorical_predictors+[target_variable]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Checking Null Values\n",
    "training_data.isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Age           0\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Sex           0\n",
       "Cabin       426\n",
       "Embarked      2\n",
       "Survived      0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "logger.info(\"Replacing Nulls\")\n",
    "training_data.replace(to_replace=[None], value=numpy.nan, inplace=True)\n",
    "training_data[numeric_predictors] = training_data.loc[:, numeric_predictors].apply(\n",
    "    pandas.to_numeric, errors=\"coerce\"\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:Replacing Nulls\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "logger.info(\"Setting 'y_train' and 'X_train'\")\n",
    "X_train = training_data.drop(\"Survived\", axis=1)\n",
    "y_train = training_data[\"Survived\"]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:Setting 'y_train' and 'X_train'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "logger.info(\"Setting up numeric transformer Pipeline\")\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:Setting up numeric transformer Pipeline\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "logger.info(\"Setting up categorical transformer Pipeline\")\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:Setting up categorical transformer Pipeline\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "logger.info(\"Initializing preprocessor\")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_predictors),\n",
    "        (\"cat\", categorical_transformer, categorical_predictors),\n",
    "    ]\n",
    ")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:Initializing preprocessor\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "logger.info(\"Initializing model pipeline\")\n",
    "model = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier())]\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:Initializing model pipeline\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "logger.info(\"Fitting model\")\n",
    "model.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:Fitting model\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='mean',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean=T...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "logger.info(\"Model fitting complete. Writing RFC_model.pkl to outputDir\")\n",
    "with open(\"RFC_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:Model fitting complete. Writing RFC_model.pkl to outputDir\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Let's check Performance on test data\n",
    "test_data = pandas.read_csv(\"test.csv\")\n",
    "test_data = test_data[numeric_predictors+categorical_predictors+[target_variable]]\n",
    "\n",
    "test_accuracy = model.score(\n",
    "    test_data[numeric_predictors+categorical_predictors],test_data[\"Survived\"]\n",
    ")\n",
    "logger.info(\"Accuracy on training data %f: \", test_accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:Accuracy on training data 0.811189: \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Let's score New Data (no ground truth)\n",
    "new_data = pandas.read_csv(\"predict.csv\")\n",
    "new_scores = model.predict(new_data[numeric_predictors+categorical_predictors])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "\n",
    "\n",
    "# modelop.init\n",
    "def begin():\n",
    "\n",
    "    global model\n",
    "    model = pickle.load(open(\"RFC_model.pkl\", \"rb\"))\n",
    "    logger.info(\"'RFC_model.pkl' file loaded to global variable 'model'\")\n",
    "\n",
    "    global numeric_predictors, categorical_predictors, target_variable\n",
    "    numeric_predictors = [\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]\n",
    "    categorical_predictors = [\"Sex\", \"Cabin\", \"Embarked\"]\n",
    "    target_variable = \"Survived\"\n",
    "    logger.info(\"Variable roles assigned\")\n",
    "\n",
    "\n",
    "# modelop.score\n",
    "def predict(scoring_data):\n",
    "\n",
    "    logger.info(\"scoring_data is of type: %s\", type(scoring_data))\n",
    "\n",
    "    scoring_df = pandas.DataFrame(scoring_data, index=[0])\n",
    "    scoring_df[\"Prediction\"] = model.predict(\n",
    "        scoring_df[numeric_predictors+categorical_predictors]\n",
    "    )\n",
    "    yield scoring_df.to_dict(orient='records')\n",
    "\n",
    "\n",
    "# modelop.metrics\n",
    "def metrics(metrics_df):\n",
    "\n",
    "    logger.info(\"metrics_df is of shape: %s\", metrics_df.shape)\n",
    "\n",
    "    X_test = metrics_df.drop(\"Survived\", axis=1)\n",
    "    y_true = metrics_df[\"Survived\"]\n",
    "    yield {\n",
    "        \"ACCURACY\": model.score(\n",
    "            X_test[numeric_predictors+categorical_predictors], y_true)\n",
    "    }\n",
    "\n",
    "\n",
    "# modelop.train\n",
    "def train(training_df):\n",
    "\n",
    "    logger.info(\"train_df is of shape: %s\", training_df.shape)\n",
    "    \n",
    "    training_df = training_df.loc[\n",
    "        :, numeric_predictors+categorical_predictors+[target_variable]\n",
    "    ]\n",
    "    \n",
    "    logger.info(\"Replacing Nulls\")\n",
    "    training_df.replace(to_replace=[None], value=numpy.nan, inplace=True)\n",
    "    training_df[numeric_predictors] = training_df.loc[:, numeric_predictors].apply(\n",
    "        pandas.to_numeric, errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    logger.info(\"Setting 'y_train' and 'X_train'\")\n",
    "    X_train = training_df.drop(\"Survived\", axis=1)\n",
    "    y_train = training_df[\"Survived\"]\n",
    "\n",
    "    logger.info(\"Setting up numeric transformer Pipeline\")\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logger.info(\"Setting up categorical transformer Pipeline\")\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logger.info(\"Initializing preprocessor\")\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_predictors),\n",
    "            (\"cat\", categorical_transformer, categorical_predictors),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logger.info(\"Initializing model pipeline\")\n",
    "    model = Pipeline(\n",
    "        steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier())]\n",
    "    )\n",
    "\n",
    "    logger.info(\"Fitting model\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # pickle file should be written to outputDir/\n",
    "    logger.info(\"Model fitting complete. Writing 'RFC_model.pkl' to outputDir/\")\n",
    "    with open(\"outputDir/RFC_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    logger.info(\"Training Job Complete!\")\n",
    "    pass\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "predict_data = pandas.read_csv(\"predict.csv\")\n",
    "test_data = pandas.read_csv(\"test.csv\")\n",
    "training_data = pandas.read_csv(\"train.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "begin()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:'RFC_model.pkl' file loaded to global variable 'model'\n",
      "INFO:__main__:Variable roles assigned\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "next(predict(predict_data))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:scoring_data is of type: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'PassengerId': 871,\n",
       "  'Pclass': 3,\n",
       "  'Name': 'Balkic, Mr. Cerin',\n",
       "  'Sex': 'male',\n",
       "  'Age': 26.0,\n",
       "  'SibSp': 0,\n",
       "  'Parch': 0,\n",
       "  'Ticket': '349248',\n",
       "  'Fare': 7.8958,\n",
       "  'Cabin': nan,\n",
       "  'Embarked': 'S',\n",
       "  'Prediction': 0}]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "next(metrics(test_data))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:metrics_df is of shape: (143, 12)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ACCURACY': 0.8251748251748252}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "train(training_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:__main__:train_df is of shape: (571, 12)\n",
      "INFO:__main__:Replacing Nulls\n",
      "INFO:__main__:Setting 'y_train' and 'X_train'\n",
      "INFO:__main__:Setting up numeric transformer Pipeline\n",
      "INFO:__main__:Setting up categorical transformer Pipeline\n",
      "INFO:__main__:Initializing preprocessor\n",
      "INFO:__main__:Initializing model pipeline\n",
      "INFO:__main__:Fitting model\n",
      "INFO:__main__:Model fitting complete. Writing 'RFC_model.pkl' to outputDir/\n",
      "INFO:__main__:Training Job Complete!\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('modelop': conda)"
  },
  "interpreter": {
   "hash": "1bc0af681b6debbd76b10de7ba3014cd62e1e3ee55e8e9a892bbbe23fd8d618c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}